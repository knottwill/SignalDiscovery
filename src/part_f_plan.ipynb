{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of data\n",
    "\n",
    "Make `generation.py` module containing `generate_from_total_pdf(N_events, f=0.1, ...)`\n",
    "\n",
    "We generate `n` datasets at different values of `N` (size of dataset).\n",
    "\n",
    "For a given `N`, should I run 'pilot simulations', to inform what choice for `n` is needed to get a good estimate of the probability of success. We could decide what we want the size of $\\hat{\\sigma_i}$ to be (roughly), as a percentage of $\\hat{p_i}$, (eg. 5%) and then solve for $n_i$ in the equation:\n",
    "\n",
    "$\\hat{\\sigma_i} = \\sqrt{\\frac{\\hat{p_i}(1-\\hat{p_i})}{n_i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis test on each dataset\n",
    "\n",
    "Use Matt's example for the higgs discovery in lecture 16 as guidance.\n",
    "\n",
    "We fit the background only model and total model to the dataset, using MLE (or another estimation method).\n",
    "\n",
    "Calculate the neyman-pearson test statistic (I think `iminuit` can do this automatically).\n",
    "\n",
    "Assume: this test statistic, given the null hypothesis, is chi squared distributed with k=1. Is this a valid assumption? I think its only true in the asymptotic limit of high N. On the other hand, it may he the only way to conduct the hypothesis test, so if N is too small for this assumption to be valid, then N may be too small for discovery.\n",
    "\n",
    "`p = 1 - chi2.cdf(T, 1)`\n",
    "\n",
    "Then its a one sided test so the significance is:\n",
    "\n",
    "`Z = np.sqrt(chi2.ppf(1-2p, 1))`\n",
    "\n",
    "If Z>=5 then we have 'discovered the signal' (success)\n",
    "\n",
    "I will have a module for this: `hypothesis_test.py`\n",
    "\n",
    "#### Statistical justification of the assumption\n",
    "\n",
    "I think I need to justify \"this test statistic, given the null hypothesis, is chi squared distributed with k=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial dataset\n",
    "\n",
    "After conducting hypothesis test on all datasets for a given $N_i$, we have essentailly conducted a Bernoulli trial, where the number of discoveries (successes), `r`, is binomially distributed, except the probability of success, $p_N$, is unknown. \n",
    "\n",
    "We estimate $\\hat{p_i} = r/n$, where $n$ is the number of trials\n",
    "\n",
    "And the standard error on this estimate is $\\hat{\\sigma_i} = \\sqrt{\\frac{\\hat{p_i}(1-\\hat{p_i})}{n_i}}$\n",
    "\n",
    "Alternatively could we construct a confidence belt???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p vs N\n",
    "\n",
    "Once we have our dataset of $\\{ N_i, \\hat{p_i} \\pm \\hat{\\sigma_i} \\}$, we can plot $p$ vs $N$, fit a line of best fit.\n",
    "\n",
    "We would need to justify the line we fit. Eg. if we fit a straight line, why would there be a linear relationship between $N$ and $p$?\n",
    "\n",
    "The line of best fit should go through 68.3% of the confidence intervals. We will discuss whether this happens.\n",
    "\n",
    "Predict $N_{discovery}$ (value of $N$ for $p=0.9$), as well as an uncertainty on $N_{discovery}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
